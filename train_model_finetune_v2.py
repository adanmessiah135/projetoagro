import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from datetime import datetime
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# ‚ú® IMPORTA√á√ÉO CORRIGIDA ‚ú®
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report

# ============================================================
# üéØ CONFIGURA√á√ïES PARA GPU (ADAPTA√á√ÉO ESPEC√çFICA)
# ============================================================
# Verifica se GPU est√° dispon√≠vel e configura
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Configura crescimento de mem√≥ria para evitar aloca√ß√£o total da GPU
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"‚úÖ GPU detectada e configurada: {len(gpus)} dispositivo(s)")
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(f"GPUs l√≥gicas dispon√≠veis: {len(logical_gpus)}")
    except RuntimeError as e:
        print(f"‚ö†Ô∏è Erro ao configurar GPU: {e}")
else:
    print("‚ö†Ô∏è Nenhuma GPU detectada. Usando CPU.")

# Opcional: Limita ao uso de 1 GPU se houver m√∫ltiplas
# tf.config.set_visible_devices(gpus[0], 'GPU')  # Descomente se quiser for√ßar 1 GPU

# Ativa mixed precision para acelerar treinamento em GPU (TensorFlow 2.4+)
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')  # Usa float16 para acelera√ß√£o, mas mant√©m estabilidade
print("üî• Mixed precision ativado para acelera√ß√£o em GPU.")

# ============================================================
# üîß CONFIGURA√á√ïES GERAIS
# ============================================================
BASE_DIR = "dataset"
IMG_SIZE = (224, 224)
BATCH_SIZE = 32  # Aumente se sua GPU tiver mais VRAM (ex: 64 para RTX 30xx+)
EPOCHS_ETAPA_1 = 30  # √âpocas para a primeira fase (Transfer Learning)
EPOCHS_ETAPA_2 = 20  # √âpocas extras para a segunda fase (Fine-Tuning)

# --- CAMINHOS DE SA√çDA (ETAPA 1) ---
OUTPUT_DIR = "ml"
MODEL_DIR = os.path.join(OUTPUT_DIR, "models")
MODEL_PATH = os.path.join(MODEL_DIR, "cana_model_v5_base.keras") # Salva o melhor modelo base

# --- CAMINHOS DE SA√çDA (ETAPA 2) ---
MODEL_PATH_FT = os.path.join(MODEL_DIR, "cana_model_v5_FINETUNED.keras")
ACCURACY_PLOT_PATH_FT = os.path.join(OUTPUT_DIR, "training_accuracy_FINETUNED.png")
CM_PLOT_PATH_FT = os.path.join(OUTPUT_DIR, "confusion_matrix_FINETUNED.png")

os.makedirs(MODEL_DIR, exist_ok=True)

print(f"\nüöÄ Iniciando Treinamento em Duas Etapas (com GPU otimizado)...")
print(f"Salvando modelo base em: {MODEL_PATH}")
print(f"Salvando modelo final em: {MODEL_PATH_FT}")

# ============================================================
# üìä GERADORES DE DADOS (VERS√ÉO CORRIGIDA)
# ============================================================

# 1. Gerador para TREINO (com Data Augmentation e pr√©-processamento)
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # <-- ‚ú® CORRE√á√ÉO CR√çTICA
    rotation_range=25,
    zoom_range=0.25,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True,
    fill_mode="nearest",
    validation_split=0.2
)

# 2. Gerador para VALIDA√á√ÉO (APENAS pr√©-processamento, SEM Augmentation)
val_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # <-- ‚ú® CORRE√á√ÉO CR√çTICA
    validation_split=0.2
)

# 3. Cria os geradores a partir das pastas
train_generator = train_datagen.flow_from_directory(
    BASE_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    color_mode="rgb",
    class_mode="categorical",
    subset="training"
)

val_generator = val_datagen.flow_from_directory(
    BASE_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    color_mode="rgb",
    class_mode="categorical",
    subset="validation",
    shuffle=False
)

# ============================================================
# ‚ÄºÔ∏è ‚ÄºÔ∏è BLOCO DE VERIFICA√á√ÉO ‚ÄºÔ∏è ‚ÄºÔ∏è
# ============================================================
print("\n" + "="*50)
print("VERIFICANDO PASTAS E CLASSES:")
print("Classes encontradas:", train_generator.class_indices)
print(f"Total de imagens de treino: {train_generator.samples}")
print(f"Total de imagens de valida√ß√£o: {val_generator.samples}")
print(f"Total de classes detectadas: {train_generator.num_classes}")
print("="*50 + "\n")

# ============================================================
# üß† ETAPA 1: CRIA√á√ÉO E TREINO DO MODELO BASE
# ============================================================
print("Iniciando Etapa 1: Treinamento do 'cabe√ßote' (Top Layers)")

# ‚ú®‚ú® ESTE √â O C√ìDIGO CORRETO PARA CRIAR O MODELO ‚ú®‚ú®
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224, 224, 3), name="mobilenet_base")
base_model.trainable = False  # Congela o modelo base

x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(256, activation="relu")(x)
x = layers.Dropout(0.3)(x)
predictions = layers.Dense(train_generator.num_classes, activation="softmax", dtype='float32')(x)  # dtype para mixed precision

model = models.Model(inputs=base_model.input, outputs=predictions)

model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-4), # LR segura para Transfer Learning
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
# Callbacks para a Etapa 1
checkpoint = ModelCheckpoint(
    MODEL_PATH, # Salva o melhor modelo DESTA etapa
    monitor="val_accuracy",
    save_best_only=True,
    verbose=1
)
early_stop = EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True # Garante que o 'model' final √© o melhor
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=3,
    min_lr=1e-7,
    verbose=1
)

history_stage1 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS_ETAPA_1,
    callbacks=[checkpoint, early_stop, reduce_lr]
)

# Opcional: Recalcula m√©tricas p√≥s-restore_best_weights para gr√°fico suave
print("Recalculando m√©tricas p√≥s-restore para gr√°fico cont√≠nuo...")
train_loss, train_acc = model.evaluate(train_generator, verbose=0)
val_loss, val_acc = model.evaluate(val_generator, verbose=0)

# Atualiza o √∫ltimo ponto do hist√≥rico (evita 'pulo' no plot)
history_stage1.history['loss'][-1] = train_loss
history_stage1.history['accuracy'][-1] = train_acc
history_stage1.history['val_loss'][-1] = val_loss
history_stage1.history['val_accuracy'][-1] = val_acc
print(f"M√©tricas atualizadas: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}")


# ============================================================
# üîì ETAPA 2: FINE-TUNING (AJUSTE FINO)
# ============================================================
print("\n" + "="*50)
print(f"Iniciando Etapa 2: Fine-Tuning (continuando do melhor da Etapa 1)")
print("Descongelando camadas superiores do base_model...")
print("="*50 + "\n")

# Opcional: Se quiser carregar o modelo salvo (garante o melhor, mas reinicia otimizador)
# model = models.load_model(MODEL_PATH)
# print(f"Modelo carregado de: {MODEL_PATH}")
# Nesse caso, mude o freeze para: for layer in model.layers[:fine_tune_at]: layer.trainable = False
# E set epochs=EPOCHS_ETAPA_2, initial_epoch=0

# Usa a refer√™ncia original do base_model (j√° em escopo, sem get_layer!)
base_model.trainable = True  # Descongela TODO o base_model

# Congela as primeiras 100 camadas do base_model (early layers)
fine_tune_at = 100
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
print(f"Camadas congeladas: 0 a {fine_tune_at-1} (base_model tem {len(base_model.layers)} camadas)")

# Recompila com LR baixa
model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-5), # 0.00001
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# Callbacks para a Etapa 2 (salva em caminhos diferentes)
checkpoint_ft = ModelCheckpoint(
    MODEL_PATH_FT, # Salva o melhor modelo de FINE-TUNING
    monitor="val_accuracy",
    save_best_only=True,
    verbose=1
)

early_stop_ft = EarlyStopping(
    monitor="val_loss",
    patience=5, # 5 √©pocas de paci√™ncia para o fine-tuning
    restore_best_weights=True
)

# Continua o treinamento (fine-tuning) - CORRIGIDO: √©pocas exatas
num_epochs_stage1 = len(history_stage1.history['loss'])
history_stage2 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=num_epochs_stage1 + EPOCHS_ETAPA_2, # Corrige: rodadas na 1 + 20 extras
    initial_epoch=num_epochs_stage1,
    callbacks=[checkpoint_ft, early_stop_ft, reduce_lr] # Re-usa o reduce_lr
)

# ============================================================
# üìà RELAT√ìRIO DE RESULTADOS (COMBINADO)
# ============================================================
# Combina o hist√≥rico das duas etapas para um gr√°fico completo
acc = history_stage1.history['accuracy'] + history_stage2.history['accuracy']
val_acc = history_stage1.history['val_accuracy'] + history_stage2.history['val_accuracy']
loss = history_stage1.history['loss'] + history_stage2.history['loss']
val_loss = history_stage1.history['val_loss'] + history_stage2.history['val_loss']

# Plota a acur√°cia combinada
plt.figure(figsize=(12, 6))
plt.plot(acc, label="Treino")
plt.plot(val_acc, label="Valida√ß√£o")
# Marca o in√≠cio do Fine-Tuning - CORRIGIDO
plt.axvline(x=num_epochs_stage1 - 1, color='red', linestyle='--', label='In√≠cio do Fine-Tuning')
plt.title("Acur√°cia do Modelo (Completo: Transfer + Fine-Tuning)")
plt.xlabel("√âpocas")
plt.ylabel("Acur√°cia")
plt.legend()
plt.tight_layout()
plt.savefig(ACCURACY_PLOT_PATH_FT) # Salva o novo gr√°fico
plt.show()

# ============================================================
# üß† RELAT√ìRIO AUTOM√ÅTICO DE CONFIAN√áA (P√ìS-ETAPA 2)
# ============================================================
# Pega o melhor resultado da Etapa 2 (ou Etapa 1 se a 2 n√£o melhorar)
final_val_acc = max(val_acc) * 100
if final_val_acc >= 80:
    interpretacao = "Alta confian√ßa ‚úÖ ‚Äî modelo muito consistente."
elif final_val_acc >= 65:
    interpretacao = "Confian√ßa m√©dia üî∂ ‚Äî modelo razo√°vel."
else:
    interpretacao = "Confian√ßa baixa ‚ö†Ô∏è ‚Äî modelo precisa de mais dados."

print(f"\nüìä Acur√°cia final de valida√ß√£o: {final_val_acc:.2f}%")
print(f"üí¨ Interpreta√ß√£o: {interpretacao}")

# ============================================================
# üìâ MATRIZ DE CONFUS√ÉO E RELAT√ìRIO POR CLASSE (P√ìS-ETAPA 2)
# ============================================================
print("\nüìä Gerando matriz de confus√£o e relat√≥rio (Modelo Final P√≥s-Fine-Tuning)...")

# O 'model' j√° foi restaurado para o melhor da Etapa 2 pelo EarlyStopping
y_pred = model.predict(val_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = val_generator.classes
class_labels = list(val_generator.class_indices.keys())

# Matriz de confus√£o normalizada
cm = confusion_matrix(y_true, y_pred_classes, normalize="true")
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, cmap="Blues", fmt=".2f", xticklabels=class_labels, yticklabels=class_labels)
plt.title("Matriz de Confus√£o Normalizada (Modelo Final P√≥s-Fine-Tuning)")
plt.xlabel("Predito")
plt.ylabel("Real")
plt.tight_layout()
plt.savefig(CM_PLOT_PATH_FT) # ‚ú® CORRE√á√ÉO: Salva no caminho correto
plt.show()

# Relat√≥rio detalhado
report = classification_report(y_true, y_pred_classes, target_names=class_labels)
print("\nüìã Relat√≥rio de Classifica√ß√£o (Modelo Final P√≥s-Fine-Tuning):\n")
print(report)

print(f"\n‚úÖ Fine-tuning conclu√≠do e salvo em: {MODEL_PATH_FT}") # ‚ú® CORRE√á√ÉO: Mostra o caminho correto
print("üß† Classes detectadas:", class_labels)

# ============================================================
# üß™ TESTE R√ÅPIDO EM IMAGEM NOVA (OPCIONAL - CORRIGIDO)
# ============================================================
# Descomente e ajuste o path para testar uma imagem nova
# from tensorflow.keras.preprocessing import image
# img_path = "path/to/sua_imagem_teste.jpg"  # Troque pelo path real
# img = image.load_img(img_path, target_size=IMG_SIZE)
# img_array = image.img_to_array(img)
# img_array_expanded = np.expand_dims(img_array, axis=0)
# img_preprocessed = preprocess_input(img_array_expanded) # ‚ú® CORRE√á√ÉO: Usa preprocess_input
#
# pred = model.predict(img_preprocessed)
# class_idx = np.argmax(pred)
# confidence = pred[0][class_idx]
# print(f"\nüß™ Predi√ß√£o em imagem de teste: {class_labels[class_idx]} (confian√ßa: {confidence:.2f})")

